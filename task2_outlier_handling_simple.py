# ============================================================================
# TASK 2: MANEJO DE OUTLIERS EN MODELOS DE REGRESI√ìN
# Versi√≥n simplificada para desarrolladores junior
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, HuberRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler

# ============================================================================
# PASO 1: CARGAR Y EXPLORAR LOS DATOS
# ============================================================================

def cargar_datos():
    """Carga el archivo CSV y muestra informaci√≥n b√°sica"""
    print("=== PASO 1: CARGANDO DATOS ===")
    
    # Leer el archivo CSV
    datos = pd.read_csv('p3_task-2.csv')
    
    print(f"üìä Forma del dataset: {datos.shape}")
    print(f"üìã Columnas: {list(datos.columns)}")
    print(f"üéØ Variable objetivo: {datos.columns[-1]}")
    
    # Mostrar las primeras filas
    print("\nüìÑ Primeras 5 filas:")
    print(datos.head())
    
    # Mostrar estad√≠sticas b√°sicas
    print("\nüìà Estad√≠sticas b√°sicas:")
    print(datos.describe())
    
    return datos

# ============================================================================
# PASO 2: DIVIDIR LOS DATOS EN ENTRENAMIENTO Y PRUEBA
# ============================================================================

def dividir_datos(datos):
    """Divide los datos en 80% para entrenar y 20% para probar"""
    print("\n=== PASO 2: DIVIDIENDO DATOS ===")
    
    # Separar features (X) y target (y)
    X = datos.drop('y', axis=1)  # Todas las columnas excepto 'y'
    y = datos['y']               # Solo la columna 'y'
    
    # Dividir en train (80%) y test (20%)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=0.2,           # 20% para test
        random_state=42          # Para resultados reproducibles
    )
    
    print(f"‚úÖ Datos de entrenamiento: {X_train.shape[0]} muestras")
    print(f"‚úÖ Datos de prueba: {X_test.shape[0]} muestras")
    print(f"‚úÖ Features: {list(X.columns)}")
    
    return X_train, X_test, y_train, y_test

# ============================================================================
# PASO 3: EXPLORAR LOS DATOS DE ENTRENAMIENTO
# ============================================================================

def explorar_datos_entrenamiento(X_train, y_train):
    """Explora los datos de entrenamiento para encontrar outliers"""
    print("\n=== PASO 3: EXPLORANDO DATOS DE ENTRENAMIENTO ===")
    
    # Crear gr√°fico simple
    plt.figure(figsize=(12, 8))
    
    # Gr√°fico 1: Distribuci√≥n de cada feature
    plt.subplot(2, 2, 1)
    X_train.boxplot()
    plt.title('Distribuci√≥n de Features (Box Plots)')
    plt.ylabel('Valores')
    
    # Gr√°fico 2: x1 vs y
    plt.subplot(2, 2, 2)
    plt.scatter(X_train['x1'], y_train, alpha=0.6)
    plt.xlabel('x1')
    plt.ylabel('y')
    plt.title('x1 vs y')
    
    # Gr√°fico 3: x2 vs y
    plt.subplot(2, 2, 3)
    plt.scatter(X_train['x2'], y_train, alpha=0.6)
    plt.xlabel('x2')
    plt.ylabel('y')
    plt.title('x2 vs y')
    
    # Gr√°fico 4: x3 vs y
    plt.subplot(2, 2, 4)
    plt.scatter(X_train['x3'], y_train, alpha=0.6)
    plt.xlabel('x3')
    plt.ylabel('y')
    plt.title('x3 vs y')
    
    plt.tight_layout()
    plt.savefig('exploracion_datos.png')
    plt.show()
    
    # Buscar outliers usando el m√©todo IQR
    print("\nüîç Buscando outliers:")
    for feature in ['x1', 'x2', 'x3']:
        # Calcular Q1, Q3 e IQR
        Q1 = X_train[feature].quantile(0.25)  # Primer cuartil
        Q3 = X_train[feature].quantile(0.75)  # Tercer cuartil
        IQR = Q3 - Q1                         # Rango intercuart√≠lico
        
        # Definir l√≠mites para outliers
        limite_inferior = Q1 - 1.5 * IQR
        limite_superior = Q3 + 1.5 * IQR
        
        # Contar outliers
        outliers = X_train[(X_train[feature] < limite_inferior) | 
                          (X_train[feature] > limite_superior)]
        
        print(f"   {feature}: {len(outliers)} outliers encontrados")

# ============================================================================
# PASO 4: REMOVER OUTLIERS DE LOS DATOS DE ENTRENAMIENTO
# ============================================================================

def remover_outliers(X_train, y_train):
    """Remueve outliers de los datos de entrenamiento"""
    print("\n=== PASO 4: REMOVIENDO OUTLIERS ===")
    
    # Guardar tama√±o original
    tama√±o_original = len(X_train)
    
    # Copiar datos para no modificar los originales
    X_limpio = X_train.copy()
    y_limpio = y_train.copy()
    
    # Para cada feature, remover outliers
    for feature in ['x1', 'x2', 'x3']:
        # Calcular l√≠mites
        Q1 = X_limpio[feature].quantile(0.25)
        Q3 = X_limpio[feature].quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior = Q1 - 1.5 * IQR
        limite_superior = Q3 + 1.5 * IQR
        
        # Filtrar datos (mantener solo los que NO son outliers)
        mascara = (X_limpio[feature] >= limite_inferior) & (X_limpio[feature] <= limite_superior)
        X_limpio = X_limpio[mascara]
        y_limpio = y_limpio[mascara]
    
    # Mostrar resultados
    datos_removidos = tama√±o_original - len(X_limpio)
    print(f"üìä Datos originales: {tama√±o_original}")
    print(f"üìä Datos despu√©s de limpiar: {len(X_limpio)}")
    print(f"üóëÔ∏è  Outliers removidos: {datos_removidos}")
    
    return X_limpio, y_limpio

# ============================================================================
# PASO 5: ENTRENAR Y EVALUAR LOS TRES MODELOS
# ============================================================================

def entrenar_modelos(X_train, X_train_limpio, X_test, y_train, y_train_limpio, y_test):
    """Entrena y eval√∫a los tres modelos de regresi√≥n"""
    print("\n=== PASO 5: ENTRENANDO MODELOS ===")
    
    # Normalizar los datos (importante para que los modelos funcionen mejor)
    scaler = StandardScaler()
    
    # ===== MODELO 1: Regresi√≥n Lineal CON outliers =====
    print("\n1Ô∏è‚É£  Regresi√≥n Lineal (CON outliers):")
    
    # Normalizar datos de entrenamiento
    X_train_normalizado = scaler.fit_transform(X_train)
    X_test_normalizado = scaler.transform(X_test)
    
    # Crear y entrenar modelo
    modelo_lr_con_outliers = LinearRegression()
    modelo_lr_con_outliers.fit(X_train_normalizado, y_train)
    
    # Predecir y evaluar
    predicciones_lr_con_outliers = modelo_lr_con_outliers.predict(X_test_normalizado)
    mae_lr_con_outliers = mean_absolute_error(y_test, predicciones_lr_con_outliers)
    print(f"   üìä MAE: {mae_lr_con_outliers:.2f}")
    
    # ===== MODELO 2: Regresi√≥n Huber (robusto a outliers) =====
    print("\n2Ô∏è‚É£  Regresi√≥n Huber (robusto a outliers):")
    
    # Crear y entrenar modelo Huber
    modelo_huber = HuberRegressor(epsilon=1.35, max_iter=1000)
    modelo_huber.fit(X_train_normalizado, y_train)
    
    # Predecir y evaluar
    predicciones_huber = modelo_huber.predict(X_test_normalizado)
    mae_huber = mean_absolute_error(y_test, predicciones_huber)
    print(f"   üìä MAE: {mae_huber:.2f}")
    
    # ===== MODELO 3: Regresi√≥n Lineal SIN outliers =====
    print("\n3Ô∏è‚É£  Regresi√≥n Lineal (SIN outliers):")
    
    # Normalizar datos limpios
    X_train_limpio_normalizado = scaler.fit_transform(X_train_limpio)
    X_test_normalizado = scaler.transform(X_test)
    
    # Crear y entrenar modelo
    modelo_lr_sin_outliers = LinearRegression()
    modelo_lr_sin_outliers.fit(X_train_limpio_normalizado, y_train_limpio)
    
    # Predecir y evaluar
    predicciones_lr_sin_outliers = modelo_lr_sin_outliers.predict(X_test_normalizado)
    mae_lr_sin_outliers = mean_absolute_error(y_test, predicciones_lr_sin_outliers)
    print(f"   üìä MAE: {mae_lr_sin_outliers:.2f}")
    
    # Guardar resultados
    resultados = {
        'lr_con_outliers': mae_lr_con_outliers,
        'huber': mae_huber,
        'lr_sin_outliers': mae_lr_sin_outliers
    }
    
    return resultados

# ============================================================================
# PASO 6: COMPARAR LOS MODELOS
# ============================================================================

def comparar_modelos(resultados):
    """Compara el rendimiento de los tres modelos"""
    print("\n=== PASO 6: COMPARANDO MODELOS ===")
    
    # Crear tabla de comparaci√≥n
    print("\nüìä Comparaci√≥n de Modelos:")
    print("=" * 50)
    print(f"{'Modelo':<35} {'MAE':<10}")
    print("=" * 50)
    print(f"{'Regresi√≥n Lineal (con outliers)':<35} {resultados['lr_con_outliers']:<10.2f}")
    print(f"{'Regresi√≥n Huber':<35} {resultados['huber']:<10.2f}")
    print(f"{'Regresi√≥n Lineal (sin outliers)':<35} {resultados['lr_sin_outliers']:<10.2f}")
    print("=" * 50)
    
    # Encontrar el mejor modelo
    mejor_mae = min(resultados.values())
    mejor_modelo = [k for k, v in resultados.items() if v == mejor_mae][0]
    
    print(f"\nüèÜ MEJOR MODELO: {mejor_modelo}")
    print(f"üìä Mejor MAE: {mejor_mae:.2f}")
    
    # Calcular mejoras
    mae_baseline = resultados['lr_con_outliers']
    mejora_huber = ((mae_baseline - resultados['huber']) / mae_baseline) * 100
    mejora_limpio = ((mae_baseline - resultados['lr_sin_outliers']) / mae_baseline) * 100
    
    print(f"\nüìà Mejoras respecto al baseline:")
    print(f"   Regresi√≥n Huber: {mejora_huber:.1f}% de mejora")
    print(f"   Regresi√≥n Lineal (limpia): {mejora_limpio:.1f}% de mejora")
    
    # Crear gr√°fico simple
    plt.figure(figsize=(10, 6))
    
    modelos = ['LR (con outliers)', 'Huber', 'LR (sin outliers)']
    maes = [resultados['lr_con_outliers'], resultados['huber'], resultados['lr_sin_outliers']]
    colores = ['red', 'blue', 'green']
    
    barras = plt.bar(modelos, maes, color=colores, alpha=0.7)
    plt.title('Comparaci√≥n de Modelos (MAE)', fontsize=14, fontweight='bold')
    plt.ylabel('Error Absoluto Medio (MAE)')
    plt.grid(True, alpha=0.3)
    
    # Agregar valores en las barras
    for barra, mae in zip(barras, maes):
        altura = barra.get_height()
        plt.text(barra.get_x() + barra.get_width()/2., altura + 1,
                f'{mae:.1f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('comparacion_modelos.png')
    plt.show()

# ============================================================================
# PASO 7: CONCLUSIONES
# ============================================================================

def mostrar_conclusiones():
    """Muestra las conclusiones del an√°lisis"""
    print("\n=== PASO 7: CONCLUSIONES ===")
    
    print("""
üìã RESUMEN DE HALLAZGOS:

‚úÖ Los outliers afectan negativamente el rendimiento de la regresi√≥n lineal est√°ndar

‚úÖ La regresi√≥n Huber es m√°s robusta a outliers y mejora el rendimiento

‚úÖ Remover outliers del entrenamiento mejora el modelo de regresi√≥n lineal

‚úÖ Ambos m√©todos (Huber y limpieza de datos) son mejores que usar regresi√≥n 
   lineal con outliers

üí° RECOMENDACIONES:

1. Para datasets con outliers, usar regresi√≥n Huber
2. Si es posible, limpiar outliers del entrenamiento
3. Siempre evaluar en un conjunto de prueba separado
4. Comparar m√∫ltiples enfoques antes de decidir

üéØ RESULTADO ESPERADO:
Como se esperaba, tanto la regresi√≥n Huber como la regresi√≥n lineal en datos 
limpios superan al modelo lineal entrenado con outliers.
    """)

# ============================================================================
# FUNCI√ìN PRINCIPAL
# ============================================================================

def main():
    """Funci√≥n principal que ejecuta todo el an√°lisis"""
    print("üöÄ INICIANDO AN√ÅLISIS DE OUTLIERS")
    print("=" * 50)
    
    # Paso 1: Cargar datos
    datos = cargar_datos()
    
    # Paso 2: Dividir datos
    X_train, X_test, y_train, y_test = dividir_datos(datos)
    
    # Paso 3: Explorar datos de entrenamiento
    explorar_datos_entrenamiento(X_train, y_train)
    
    # Paso 4: Remover outliers
    X_train_limpio, y_train_limpio = remover_outliers(X_train, y_train)
    
    # Paso 5: Entrenar modelos
    resultados = entrenar_modelos(X_train, X_train_limpio, X_test, y_train, y_train_limpio, y_test)
    
    # Paso 6: Comparar modelos
    comparar_modelos(resultados)
    
    # Paso 7: Mostrar conclusiones
    mostrar_conclusiones()
    
    print("\n‚úÖ ¬°AN√ÅLISIS COMPLETADO!")
    print("üìÅ Archivos generados:")
    print("   - exploracion_datos.png")
    print("   - comparacion_modelos.png")

# Ejecutar el programa
if __name__ == "__main__":
    main() 